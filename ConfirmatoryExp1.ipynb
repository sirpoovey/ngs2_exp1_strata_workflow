{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGSS WITNESS Experiment 2 using Bedrock\n",
    "\n",
    "# Pre-registration summary\n",
    "\n",
    "+ The experiment was pre-registered on 2017-04-04, and the pre-registration form is available at https://osf.io/6jvw9/.\n",
    "+ The experiment was later amended on 2017-07-07 per https://osf.io/ngwqa/.\n",
    "+ And amended again on 2017-08-08 per https://osf.io/qymzh/.\n",
    "\n",
    "## Experimental design:\n",
    "\n",
    "+ Each player resides on a nonweighted network, with 20% possible links formed at *random*.\n",
    "+ His/her *neighbors* are players connected to him/her on this network.\n",
    "+ Each player exercises one of the following two actions during each round of the game.\n",
    "    - Cooperation: paying 50 units for each neighbor and results in 100 units gain for each neighbor. \n",
    "    - Defection: paying nothing and generating no benefits.\n",
    "+ Before each round, players are reminded of their number of neighbors and these neighbors' prior decisions. \n",
    "+ After each round, players learn about the decisions of their neighbors and their own payoff.\n",
    "+ The probability for each subsequent round is 0.8, which was communicated to players. \n",
    "\n",
    "## Experimental conditions:\n",
    "\n",
    "At the beginning of the experiment, the social network isinitialized with 20% of possible links being formed at random. We examine three kinds of network conditions: random link updating, fixed links, and strategic link updating.\n",
    "\n",
    "+ **Fixed** links: the network is static for the duration of the experiment\n",
    "+ **Random** link updating: the social network is regenerated randomly after every round\n",
    "+ Strategic link updating: a rewiring step following each round. Subject pairs are randomly selected and one randomly selected actor of the selected pair will be given the option to change the status between the pair (connected to disconnected, or disconnected to connected.) The deciding actor will be provided with behavior of the alter's during the previous round. At the end of the rewiring step, each player will receive summaries about updates involved him/her. \n",
    "    - **Viscous**: 10% randomly picked subject pairs selected to have an option of change.\n",
    "    - **Fluid**: 30% randomly picked subject pairs selected to have an option of change.\n",
    "\n",
    "\n",
    "# Links to other documents in this submission \n",
    "\n",
    "+ Power Analysis for Experiment 1 https://osf.io/tc8un/\n",
    "+ World Lab Empanelment Screener https://osf.io/z5cjm/\n",
    "+ Original article by Rand et al. (2011) https://osf.io/74etg/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bedrock Requirements to Run this Experiment\n",
    "\n",
    "* [Spreadsheet](https://github.com/Bedrock-py/opal-dataloader-ingest-spreadsheet)\n",
    "* [logit2](https://github.com/Bedrock-py/opal-analytics-logit2)\n",
    "* [select-from-dataframe](https://github.com/Bedrock-py/opal-analytics-select-from-dataframe)\n",
    "* [summarize](https://github.com/Bedrock-py/opal-analytics-summarize)\n",
    "* [aggregate](https://github.com/Bedrock-py/opal-analytics-aggregate)\n",
    "* [statstests](https://github.com/Bedrock-py/opal-analytics-statstests)\n",
    "\n",
    "This notebook also requires that bedrock-core be installed locally into the python kernel running this notebook.  This can be installed via command line using:\n",
    "\n",
    "`pip install git+https://github.com/Bedrock-py/bedrock-core.git`\n",
    "\n",
    "The other requirements to run this notebook are:\n",
    "\n",
    "* [`pandas`]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check that Bedrock is installed locally.  If the following cell does not run without error, check the install procedure above and try again.  Also, ensure that the kernel selected is the same as the kernel where bedrock-core is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bedrock.client.client import BedrockAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Connection to Bedrock Server\n",
    "\n",
    "This code assumes a local bedrock is hosted at localhost on port 81.  Change the `SERVER` variable to match your server's URL and port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas\n",
    "import pprint\n",
    "SERVER = \"http://localhost:81/\"\n",
    "api = BedrockAPI(SERVER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Spreadsheet Opal\n",
    "\n",
    "The following code block checks the Bedrock server for the Spreadsheet Opal.  This Opal is used to load .csv, .xls, and other such files into a Bedrock matrix format.  The code below calls the Bedrock `/dataloaders/ingest` endpoint to check if the `opals.spreadsheet.Spreadsheet.Spreadsheet` opal is installed.\n",
    "\n",
    "If the code below shows the Opal is not installed, there are two options:\n",
    "1. If you are running a local Bedrock or are the administrator of the Bedrock server, install the Spreadsheet Opal with pip on the server [Spreadsheet](https://github.com/Bedrock-py/opal-dataloader-ingest-spreadsheet)\n",
    "2. If you are not administrator of the Bedrock server, e-mail the Bedrock administrator requesting the Opal be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = api.ingest(\"opals.spreadsheet.Spreadsheet.Spreadsheet\")\n",
    "if resp.json():\n",
    "    print(\"Spreadsheet Opal Installed!\")\n",
    "else:\n",
    "    print(\"Spreadsheet Opal Not Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for logit2 Opal\n",
    "\n",
    "The following code block checks the Bedrock server for the logit2 Opal. \n",
    "\n",
    "If the code below shows the Opal is not installed, there are two options:\n",
    "1. If you are running a local Bedrock or are the administrator of the Bedrock server, install the logit2 Opal with pip on the server [logit2](https://github.com/Bedrock-py/opal-analytics-logit2)\n",
    "2. If you are not administrator of the Bedrock server, e-mail the Bedrock administrator requesting the Opal be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = api.analytic('opals.logit2.Logit2.Logit2')\n",
    "if resp.json():\n",
    "    print(\"Logit2 Opal Installed!\")\n",
    "else:\n",
    "    print(\"Logit2 Opal Not Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for select-from-dataframe Opal\n",
    "\n",
    "The following code block checks the Bedrock server for the select-from-dataframe Opal. This allows you to filter by row and reduce the columns in a dataframe loaded by the server. \n",
    "\n",
    "If the code below shows the Opal is not installed, there are two options:\n",
    "1. If you are running a local Bedrock or are the administrator of the Bedrock server, install the select-from-datafram Opal with pip on the server [select-from-dataframe](https://github.com/Bedrock-py/opal-analytics-select-from-dataframe)\n",
    "2. If you are not administrator of the Bedrock server, e-mail the Bedrock administrator requesting the Opal be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = api.analytic('opals.select-from-dataframe.SelectByCondition.SelectByCondition')\n",
    "if resp.json():\n",
    "    print(\"Select-from-dataframe Opal Installed!\")\n",
    "else:\n",
    "    print(\"Select-from-dataframe Opal Not Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for summarize Opal\n",
    "\n",
    "The following code block checks the Bedrock server for the summarize Opal. This allows you to summarize a matrix with an optional groupby clause.\n",
    "\n",
    "If the code below shows the Opal is not installed, there are two options:\n",
    "1. If you are running a local Bedrock or are the administrator of the Bedrock server, install the summarize with pip on the server [summarize](https://github.com/Bedrock-py/opal-analytics-summarize)\n",
    "2. If you are not administrator of the Bedrock server, e-mail the Bedrock administrator requesting the Opal be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = api.analytic('opals.summarize.Summarize.Summarize')\n",
    "if resp.json():\n",
    "    print(\"Summarize Opal Installed!\")\n",
    "else:\n",
    "    print(\"Summarize Opal Not Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for aggregate Opal\n",
    "\n",
    "The following code block checks the Bedrock server for the aggregate Opal. This allows you to aggregate a matrix over a groupby clause.\n",
    "\n",
    "If the code below shows the Opal is not installed, there are two options:\n",
    "1. If you are running a local Bedrock or are the administrator of the Bedrock server, install the summarize with pip on the server [aggregate](https://github.com/Bedrock-py/opal-analytics-aggregate)\n",
    "2. If you are not administrator of the Bedrock server, e-mail the Bedrock administrator requesting the Opal be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = api.analytic('opals.aggregate.Aggregate.Aggregate')\n",
    "if resp.json():\n",
    "    print(\"Aggregate Opal Installed!\")\n",
    "else:\n",
    "    print(\"Aggregate Opal Not Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for StatsTests Opal\n",
    "\n",
    "The following code block checks the Bedrock server for the statstest Opal. This Opal contains statistical tests such as the Wilcoxon Test used in this Experiment\n",
    "\n",
    "If the code below shows the Opal is not installed, there are two options:\n",
    "1. If you are running a local Bedrock or are the administrator of the Bedrock server, install the summarize with pip on the server [statstests](https://github.com/Bedrock-py/opal-analytics-statstests)\n",
    "2. If you are not administrator of the Bedrock server, e-mail the Bedrock administrator requesting the Opal be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = api.analytic('opals.statstests.Wilcoxon.Wilcoxon')\n",
    "if resp.json():\n",
    "    print(\"Wilcoxon Test Installed!\")\n",
    "else:\n",
    "    print(\"Wilcoxon Test Not Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Data to Bedrock and Create Matrix\n",
    "\n",
    "Now that everything is installed, begin the workflow by uploading the csv data and creating a matrix.  To understand this fully, it is useful to understand how a data loading workflow occurs in Bedrock.\n",
    "\n",
    "1. Create a datasource that points to the original source file\n",
    "2. Generate a matrix from the data source (filters can be applied during this step to pre-filter the data source on load\n",
    "3. Analytics work on the generated matrix\n",
    "\n",
    "** Note: Each time a matrix is generated from a data source it will create a new copy with a new UUID to represent that matrix **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for csv file locally\n",
    "\n",
    "The following code opens the file and prints out the first part.  The file must be a csv file with a header that has labels for each column.  The file is comma delimited csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = 'cooperation_exp1.csv'\n",
    "datafile = pandas.read_csv(filepath)\n",
    "datafile.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Upload the source file to the Bedrock Server\n",
    "\n",
    "This code block uses the Spreadsheet ingest module to upload the source file to Bedrock.  ** Note: This simply copies the file to the server, but does not create a Bedrock Matrix format **\n",
    "\n",
    "If the following fails to upload. Check that the csv file is in the correct comma delimited format with headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ingest_id = 'opals.spreadsheet.Spreadsheet.Spreadsheet'\n",
    "resp = api.put_source('cooperation_exp1', ingest_id, 'default', {'file': open(filepath, \"rb\")})\n",
    "\n",
    "if resp.status_code == 201:\n",
    "    source_id = resp.json()['src_id']\n",
    "    print('Source {0} successfully uploaded'.format(filepath))\n",
    "else:\n",
    "    try:\n",
    "        print(\"Error in Upload: {}\".format(resp.json()['msg']))\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        source_id = resp.json()['src_id']\n",
    "        print(\"Using existing source.  If this is not the desired behavior, upload with a different name.\")\n",
    "    except Exception:\n",
    "        print(\"No existing source id provided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check available data sources for the CSV file\n",
    "\n",
    "Call the Bedrock sources list to see available data sources.  Note, that the `Rand2011` data source should now be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "available_sources = api.list(\"dataloader\", \"sources\").json()\n",
    "s = next(filter(lambda source: source['src_id'] == source_id, available_sources),'None')\n",
    "if s != 'None':\n",
    "    pp = pprint.PrettyPrinter()\n",
    "    pp.pprint(s)\n",
    "else:\n",
    "    print(\"Could not find source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Bedrock Matrix from the CSV Source\n",
    "\n",
    "In order to use the data, the data source must be converted to a Bedrock matrix.  The following code steps through that process.  Here we are doing a simple transform of csv to matrix.  There are options to apply filters (like renaming columns, excluding colum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resp = api.create_matrix(source_id, 'cooperation_exp1_mtx')\n",
    "mtx = resp[0]\n",
    "matrix_id = mtx['id']\n",
    "print(mtx)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at basic statistics on the source data\n",
    "\n",
    "Here we can see that Bedrock has computed some basic statistics on the source data.\n",
    "\n",
    "#### For numeric data\n",
    "\n",
    "The quartiles, max, mean, min, and standard deviation are provided\n",
    "\n",
    "#### For non-numeric data\n",
    "\n",
    "The label values and counts for each label are provided.\n",
    "\n",
    "#### For both types\n",
    "\n",
    "The proposed tags and data type that Bedrock is suggesting are provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.summarize.Summarize.Summarize\"\n",
    "inputData = {\n",
    "    'matrix.csv': mtx,\n",
    "    'features.txt': mtx\n",
    "}\n",
    "\n",
    "paramsData = []\n",
    "\n",
    "summary_mtx = api.run_analytic(analytic_id, mtx, 'cooperation_exp1_summary', input_data=inputData, parameter_data=paramsData)\n",
    "output = api.download_results_matrix(matrix_id, summary_mtx['id'], 'matrix.csv')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Filtered Matrices on each Game Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.select-from-dataframe.SelectByCondition.SelectByCondition\"\n",
    "inputData = {\n",
    "    'matrix.csv': mtx,\n",
    "    'features.txt': mtx\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"colname\",\"value\":\"condition\"},\n",
    "    {\"attrname\":\"comparator\",\"value\":\"==\"},\n",
    "    {\"attrname\":\"value\",\"value\":\"Static\"}\n",
    "]\n",
    "\n",
    "cooperation_exp1_static = api.run_analytic(analytic_id, mtx, 'cooperation_exp1_static', input_data=inputData, parameter_data=paramsData)\n",
    "\n",
    "cooperation_exp1_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.select-from-dataframe.SelectByCondition.SelectByCondition\"\n",
    "inputData = {\n",
    "    'matrix.csv': mtx,\n",
    "    'features.txt': mtx\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"colname\",\"value\":\"condition\"},\n",
    "    {\"attrname\":\"comparator\",\"value\":\"==\"},\n",
    "    {\"attrname\":\"value\",\"value\":\"Random\"}\n",
    "]\n",
    "\n",
    "cooperation_exp1_random = api.run_analytic(analytic_id, mtx, 'cooperation_exp1_random', input_data=inputData, parameter_data=paramsData)\n",
    "\n",
    "cooperation_exp1_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.select-from-dataframe.SelectByCondition.SelectByCondition\"\n",
    "inputData = {\n",
    "    'matrix.csv': mtx,\n",
    "    'features.txt': mtx\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"colname\",\"value\":\"condition\"},\n",
    "    {\"attrname\":\"comparator\",\"value\":\"==\"},\n",
    "    {\"attrname\":\"value\",\"value\":\"Viscous\"}\n",
    "]\n",
    "\n",
    "cooperation_exp1_viscous = api.run_analytic(analytic_id, mtx, 'cooperation_exp1_viscous', input_data=inputData, parameter_data=paramsData)\n",
    "\n",
    "cooperation_exp1_viscous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.select-from-dataframe.SelectByCondition.SelectByCondition\"\n",
    "inputData = {\n",
    "    'matrix.csv': mtx,\n",
    "    'features.txt': mtx\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"colname\",\"value\":\"condition\"},\n",
    "    {\"attrname\":\"comparator\",\"value\":\"==\"},\n",
    "    {\"attrname\":\"value\",\"value\":\"Fluid\"}\n",
    "]\n",
    "\n",
    "cooperation_exp1_fluid = api.run_analytic(analytic_id, mtx, 'cooperation_exp1_fluid', input_data=inputData, parameter_data=paramsData)\n",
    "\n",
    "cooperation_exp1_fluid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Rewire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = 'rewire_exp1.csv'\n",
    "datafile = pandas.read_csv(filepath)\n",
    "datafile.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Upload the source file to the Bedrock Server\n",
    "\n",
    "This code block uses the Spreadsheet ingest module to upload the source file to Bedrock.  ** Note: This simply copies the file to the server, but does not create a Bedrock Matrix format **\n",
    "\n",
    "If the following fails to upload. Check that the csv file is in the correct comma delimited format with headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ingest_id = 'opals.spreadsheet.Spreadsheet.Spreadsheet'\n",
    "resp = api.put_source('rewire_exp1', ingest_id, 'default', {'file': open(filepath, \"rb\")})\n",
    "\n",
    "if resp.status_code == 201:\n",
    "    source_id = resp.json()['src_id']\n",
    "    print('Source {0} successfully uploaded'.format(filepath))\n",
    "else:\n",
    "    try:\n",
    "        print(\"Error in Upload: {}\".format(resp.json()['msg']))\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        source_id = resp.json()['src_id']\n",
    "        print(\"Using existing source.  If this is not the desired behavior, upload with a different name.\")\n",
    "    except Exception:\n",
    "        print(\"No existing source id provided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resp = api.create_matrix(source_id, 'rewire_exp1_mtx')\n",
    "rewire_mtx = resp[0]\n",
    "rewire_matrix_id = rewire_mtx['id']\n",
    "print(rewire_mtx)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 4.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.logit2.Logit2.Logit2\"\n",
    "inputData = {\n",
    "    'matrix.csv': cooperation_exp1_static,\n",
    "    'features.txt': cooperation_exp1_static\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"formula\",\"value\":\"action ~ round\"},\n",
    "    {\"attrname\":\"family\",\"value\":\"binomial\"},\n",
    "    {\"attrname\":\"clustered_rse\",\"value\":\"session,pid\"}\n",
    "]\n",
    "\n",
    "hyp_4_1_1 = api.run_analytic(analytic_id, mtx, 'exp1_hypothesis_4_1_1', input_data=inputData, parameter_data=paramsData)\n",
    "\n",
    "hyp_4_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the output of the analysis\n",
    "\n",
    "Here the output of the analysis is downloaded and from here can be visualized and exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "coef_table = api.download_results_matrix(hyp_4_1_1['src_id'], hyp_4_1_1['id'], 'matrix.csv')\n",
    "coef_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_table = api.download_results_matrix(hyp_4_1_1['src_id'], hyp_4_1_1['id'], 'summary.csv')\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 4.1.2\n",
    "\n",
    "Randomly updating network compositions reduce exp1_cooperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.logit2.Logit2.Logit2\"\n",
    "inputData = {\n",
    "    'matrix.csv': cooperation_exp1_random,\n",
    "    'features.txt': cooperation_exp1_random\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"formula\",\"value\":\"action ~ round\"},\n",
    "    {\"attrname\":\"family\",\"value\":\"binomial\"},\n",
    "    {\"attrname\":\"clustered_rse\",\"value\":\"session,pid\"}\n",
    "]\n",
    "\n",
    "hyp_4_1_2 = api.run_analytic(analytic_id, mtx, 'exp1_hypothesis_4_1_2', input_data=inputData, parameter_data=paramsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "coef_table = api.download_results_matrix(hyp_4_1_2['src_id'], hyp_4_1_2['id'], 'matrix.csv')\n",
    "coef_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_table = api.download_results_matrix(hyp_4_1_2['src_id'], hyp_4_1_2['id'], 'summary.csv')\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 4.1.3\n",
    "\n",
    "Slowly updating strategic networks reduce exp1_cooperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.logit2.Logit2.Logit2\"\n",
    "inputData = {\n",
    "    'matrix.csv': cooperation_exp1_viscous,\n",
    "    'features.txt': cooperation_exp1_viscous\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"formula\",\"value\":\"action ~ round\"},\n",
    "    {\"attrname\":\"family\",\"value\":\"binomial\"},\n",
    "    {\"attrname\":\"clustered_rse\",\"value\":\"session,pid\"}\n",
    "]\n",
    "\n",
    "hyp_4_1_3 = api.run_analytic(analytic_id, mtx, 'exp1_hypothesis_4_1_3', input_data=inputData, parameter_data=paramsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "coef_table = api.download_results_matrix(hyp_4_1_3['src_id'], hyp_4_1_3['id'], 'matrix.csv')\n",
    "coef_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_table = api.download_results_matrix(hyp_4_1_3['src_id'], hyp_4_1_3['id'], 'summary.csv')\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 4.1.4\n",
    "\n",
    "Rapidly updating strategic networks support exp1_cooperation relative to all other conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.logit2.Logit2.Logit2\"\n",
    "inputData = {\n",
    "    'matrix.csv': mtx,\n",
    "    'features.txt': mtx\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"formula\",\"value\":\"action ~ fluid_dummy*round\"},\n",
    "    {\"attrname\":\"family\",\"value\":\"binomial\"},\n",
    "    {\"attrname\":\"clustered_rse\",\"value\":\"session,pid\"}\n",
    "]\n",
    "\n",
    "hyp_4_1_4 = api.run_analytic(analytic_id, mtx, 'exp1_hypothesis_4_1_4', input_data=inputData, parameter_data=paramsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "coef_table = api.download_results_matrix(hyp_4_1_4['src_id'], hyp_4_1_4['id'], 'matrix.csv')\n",
    "coef_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_table = api.download_results_matrix(hyp_4_1_4['src_id'], hyp_4_1_4['id'], 'summary.csv')\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 4.2.1\n",
    "\n",
    "Rapidly updating strategic networks have greater network heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.aggregate.Aggregate.Aggregate\"\n",
    "inputData = {\n",
    "    'matrix.csv': mtx,\n",
    "    'features.txt': mtx\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "  { \"name\" : \"groupby\", \"attrname\" : \"groupby\", \"value\" : \"session,fluid_dummy\", \"type\" : \"input\" },\n",
    "  { \"name\" : \"aggfuncs\", \"attrname\" : \"aggfuncs\", \"value\" : \"var\", \"type\" : \"input\" },\n",
    "  { \"name\" : \"columns\", \"attrname\" : \"columns\", \"value\" : \"num_neighbors\", \"type\" : \"input\" }\n",
    "]\n",
    "\n",
    "cooperation_neighbors_var = api.run_analytic(analytic_id, mtx, 'cooperation_neighbors_var', input_data=inputData, parameter_data=paramsData)\n",
    "f = api.download_results_matrix(cooperation_neighbors_var['src_id'], cooperation_neighbors_var['id'], 'matrix.csv', remote_header_file='features.txt')\n",
    "f.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.select-from-dataframe.SelectByCondition.SelectByCondition\"\n",
    "inputData = {\n",
    "    'matrix.csv': cooperation_neighbors_var,\n",
    "    'features.txt': cooperation_neighbors_var\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"colname\",\"value\":\"fluid_dummy\"},\n",
    "    {\"attrname\":\"comparator\",\"value\":\"==\"},\n",
    "    {\"attrname\":\"value\",\"value\":\"0\"}\n",
    "]\n",
    "\n",
    "other_var = api.run_analytic(analytic_id, cooperation_neighbors_var, 'other_var', input_data=inputData, parameter_data=paramsData)\n",
    "f = api.download_results_matrix(other_var['src_id'], other_var['id'], 'matrix.csv', remote_header_file='features.txt')\n",
    "f.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.select-from-dataframe.SelectByCondition.SelectByCondition\"\n",
    "inputData = {\n",
    "    'matrix.csv': cooperation_neighbors_var,\n",
    "    'features.txt': cooperation_neighbors_var\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"colname\",\"value\":\"fluid_dummy\"},\n",
    "    {\"attrname\":\"comparator\",\"value\":\"==\"},\n",
    "    {\"attrname\":\"value\",\"value\":\"1\"}\n",
    "]\n",
    "\n",
    "fluid_var = api.run_analytic(analytic_id, cooperation_neighbors_var, 'fluid_var', input_data=inputData, parameter_data=paramsData)\n",
    "f = api.download_results_matrix(fluid_var['src_id'], fluid_var['id'], 'matrix.csv', remote_header_file='features.txt')\n",
    "f.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.statstests.Wilcoxon.Wilcoxon\"\n",
    "inputData = {\n",
    "    'x_data.csv': fluid_var,\n",
    "    'x_features.txt': fluid_var,\n",
    "    'y_data.csv': other_var,\n",
    "    'y_features.txt': other_var,\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    { \"name\" : \"x_column\", \"attrname\" : \"x_column\", \"value\" : \"x.num_neighbors var\", \"type\" : \"input\" },\n",
    "    { \"name\" : \"y_column\", \"attrname\" : \"y_column\", \"value\" : \"y.num_neighbors var\", \"type\" : \"input\" },\n",
    "    { \"name\" : \"paired\", \"attrname\" : \"paired\" , \"value\" : \"False\", \"type\" : \"input\"}\n",
    "]\n",
    "\n",
    "hyp_4_2_1 = api.run_analytic(analytic_id, cooperation_neighbors_var, 'exp1_hypothesis_4_2_1', input_data=inputData, parameter_data=paramsData)\n",
    "f = api.download_results_matrix(hyp_4_2_1['src_id'], hyp_4_2_1['id'], 'matrix.csv')\n",
    "f.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 4.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.select-from-dataframe.SelectByComplexCondition.SelectByComplexCondition\"\n",
    "inputData = {\n",
    "    'matrix.csv': rewire_mtx,\n",
    "    'features.txt': rewire_mtx\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"condition\",\"value\":'(previouslytie == 1) & ((state==\"CC\") | (state==\"CD\") | (state==\"DC\"))'}\n",
    "]\n",
    "\n",
    "rewire_cd_dc = api.run_analytic(analytic_id, rewire_mtx, 'rewire_cd_dc', input_data=inputData, parameter_data=paramsData)\n",
    "f = api.download_results_matrix(rewire_cd_dc['src_id'], rewire_cd_dc['id'], 'matrix.csv', remote_header_file='features.txt')\n",
    "f.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.logit2.Logit2.Logit2\"\n",
    "inputData = {\n",
    "    'matrix.csv': rewire_cd_dc,\n",
    "    'features.txt': rewire_cd_dc\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"formula\",\"value\":\"C(break_tie) ~ C(CC)\"},\n",
    "    {\"attrname\":\"family\",\"value\":\"binomial\"},\n",
    "    {\"attrname\":\"clustered_rse\",\"value\":\"session,playerid\"}\n",
    "]\n",
    "\n",
    "hyp_4_2_2 = api.run_analytic(analytic_id, rewire_cd_dc, 'exp1_hypothesis_4_2_2', input_data=inputData, parameter_data=paramsData)\n",
    "coef_table = api.download_results_matrix(hyp_4_2_2['src_id'], hyp_4_2_2['id'], 'matrix.csv')\n",
    "coef_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 4.2.3\n",
    "\n",
    "Links in rapidly updating strategic networks are more stable between cooperators than between between two defectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.select-from-dataframe.SelectByComplexCondition.SelectByComplexCondition\"\n",
    "inputData = {\n",
    "    'matrix.csv': rewire_mtx,\n",
    "    'features.txt': rewire_mtx\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"condition\",\"value\":'(previouslytie == 1) & ((state==\"CC\") | (state==\"DD\"))'}\n",
    "]\n",
    "\n",
    "rewire_dd = api.run_analytic(analytic_id, rewire_mtx, 'rewire_dd', input_data=inputData, parameter_data=paramsData)\n",
    "f = api.download_results_matrix(filtered_mtx['src_id'], filtered_mtx['id'], 'matrix.csv', remote_header_file='features.txt')\n",
    "f.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.logit2.Logit2.Logit2\"\n",
    "inputData = {\n",
    "    'matrix.csv': rewire_dd,\n",
    "    'features.txt': rewire_dd\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"formula\",\"value\":\"C(break_tie) ~ C(CC)\"},\n",
    "    {\"attrname\":\"family\",\"value\":\"binomial\"},\n",
    "    {\"attrname\":\"clustered_rse\",\"value\":\"session,playerid\"}\n",
    "]\n",
    "\n",
    "hyp_4_2_3 = api.run_analytic(analytic_id, rewire_dd, 'exp1_hypothesis_4_2_3', input_data=inputData, parameter_data=paramsData)\n",
    "coef_table = api.download_results_matrix(hyp_4_2_3['src_id'], hyp_4_2_3['id'], 'matrix.csv')\n",
    "coef_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 4.2.4\n",
    "\n",
    "Cooperators have more connections than defectors in rapidly updating strategic networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.logit2.Logit2.Logit2\"\n",
    "inputData = {\n",
    "    'matrix.csv': cooperation_exp1_fluid,\n",
    "    'features.txt': cooperation_exp1_fluid\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"formula\",\"value\":\"action ~ num_neighbors\"},\n",
    "    {\"attrname\":\"family\",\"value\":\"binomial\"},\n",
    "    {\"attrname\":\"clustered_rse\",\"value\":\"session,pid\"}\n",
    "]\n",
    "\n",
    "hyp_4_2_4 = api.run_analytic(analytic_id, mtx, 'exp1_hypothesis_4_2_4', input_data=inputData, parameter_data=paramsData)\n",
    "coef_table = api.download_results_matrix(hyp_4_2_4['src_id'], hyp_4_2_4['id'], 'matrix.csv')\n",
    "coef_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
